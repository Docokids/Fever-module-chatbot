import google.generativeai as genai
from typing import List, Dict, Any
from src.models.schemas import Message
from src.providers.interface import LLMClient
from src.core.config import get_settings, Settings
from src.core.prompts import MedicalPrompts, ConversationPhase
import logging
import re

logger = logging.getLogger(__name__)

class GeminiClient(LLMClient):
    def __init__(self, settings: Settings | None = None):
        self.settings = settings or get_settings()
        logger.info(f"Initializing GeminiClient with settings: {self.settings}")
        logger.info(f"Gemini API Key present: {'Yes' if self.settings.gemini_api_key else 'No'}")
        logger.info(f"API Key length: {len(self.settings.gemini_api_key) if self.settings.gemini_api_key else 0}")
        
        if not self.settings.gemini_api_key:
            logger.error("Gemini API key is missing")
            raise ValueError("Gemini API key is required. Please set GEMINI_API_KEY environment variable or provide it in conversation settings.")
        
        try:
            genai.configure(api_key=self.settings.gemini_api_key)
            self.model = genai.GenerativeModel('gemini-2.0-flash')
            logger.info("Gemini client initialized successfully")
        except Exception as e:
            logger.error(f"Error initializing Gemini client: {str(e)}")
            raise

    async def generate(self, context: List[Message]) -> Message:
        try:
            # Verificar si hay s칤ntomas de emergencia en el 칰ltimo mensaje del usuario
            if context and context[-1].role == "user":
                safety_alert = MedicalPrompts.get_safety_check(context[-1].content)
                if safety_alert:
                    return Message(
                        role="assistant",
                        content=f"游뚿 {safety_alert}\n\nPor favor, busca atenci칩n m칠dica inmediata. Esta informaci칩n no reemplaza la consulta m칠dica profesional."
                    )

            # Generar el prompt contextual basado en el historial
            conversation_history = [
                {"role": msg.role, "content": msg.content} 
                for msg in context
            ]
            
            # Determinar la fase de la conversaci칩n
            phase = MedicalPrompts._determine_phase(conversation_history)
            logger.info(f"Conversation phase: {phase.value}")
            
            # Analizar el contexto para determinar qu칠 informaci칩n ya tenemos
            context_info = self._analyze_conversation_context(conversation_history)
            
            # Generar el prompt contextual con la fase espec칤fica
            system_prompt = MedicalPrompts.get_contextual_prompt(conversation_history, phase)
            
            # Agregar instrucciones espec칤ficas para control de preguntas
            if phase in [ConversationPhase.INITIAL, ConversationPhase.DISCOVERY]:
                system_prompt += "\n\nCONTROL DE PREGUNTAS:\n"
                system_prompt += "- DEBES hacer SOLO UNA pregunta en tu respuesta\n"
                system_prompt += "- NO hagas m칰ltiples preguntas\n"
                system_prompt += "- NO hagas listas de preguntas\n"
                system_prompt += "- Tu respuesta debe terminar con una sola pregunta\n"
                
                # Agregar la pregunta espec칤fica que debe hacer
                specific_question = MedicalPrompts.get_specific_question_for_phase(phase, context_info)
                system_prompt += f"- DEBES hacer esta pregunta espec칤fica: '{specific_question}'\n"
                system_prompt += f"- Ejemplo de respuesta correcta: 'Hola, soy el pediatra de DocoKids. {specific_question}'\n"
            
            # Crear el mensaje del sistema
            system_message = {
                "role": "user",
                "parts": [system_prompt]
            }
            
            # Crear el historial de mensajes para Gemini
            messages = [system_message]
            
            # Agregar el historial de la conversaci칩n
            for msg in context:
                messages.append({
                    "role": msg.role,
                    "parts": [msg.content]
                })
            
            # Generar la respuesta usando el modelo
            response = self.model.generate_content(messages)
            
            # Extraer el texto de la respuesta
            response_text = response.text
            
            # Validar y corregir la respuesta para asegurar que tenga la pregunta correcta
            if phase in [ConversationPhase.INITIAL, ConversationPhase.DISCOVERY]:
                response_text = self._force_specific_question(response_text, phase, context_info)
            
            # Asegurar que la respuesta sea apropiada para el contexto m칠dico
            if not response_text.strip():
                if phase == ConversationPhase.INITIAL:
                    response_text = "Hola, soy el pediatra de DocoKids. 쮺u치l es la edad del ni침o?"
                else:
                    specific_question = MedicalPrompts.get_specific_question_for_phase(phase, context_info)
                    response_text = f"Entiendo tu preocupaci칩n. {specific_question}"
            
            logger.info(f"Generated response for phase {phase.value}: {response_text[:100]}...")
            
            return Message(
                role="assistant",
                content=response_text
            )
            
        except Exception as e:
            logger.error(f"Error generating response: {str(e)}")
            # Respuesta de fallback
            return Message(
                role="assistant",
                content="Disculpa, estoy teniendo dificultades t칠cnicas. Por favor, consulta directamente con un pediatra para obtener la mejor atenci칩n para tu hijo."
            )

    def _analyze_conversation_context(self, conversation_history: List[Dict[str, Any]]) -> Dict[str, Any]:
        """Analiza el historial de conversaci칩n para extraer informaci칩n clave"""
        context_info = {
            'has_age': False,
            'has_symptom': False,
            'symptom': None,
            'age': None
        }
        
        user_messages = [msg for msg in conversation_history if msg.get('role') == 'user']
        
        for msg in user_messages:
            content = msg.get('content', '').lower()
            
            # Detectar edad
            age_patterns = [
                r'(\d+)\s*(a침os?|meses?|mes|a침o)',
                r'edad\s*(?:del\s*nino|es)\s*(\d+)',
                r'(\d+)\s*(?:a침os?|meses?)'
            ]
            
            for pattern in age_patterns:
                match = re.search(pattern, content)
                if match:
                    context_info['has_age'] = True
                    context_info['age'] = match.group(1)
                    break
            
            # Detectar s칤ntomas
            symptoms = {
                'fiebre': ['fiebre', 'temperatura', 'caliente', 'febril'],
                'tos': ['tos', 'tose', 'tosiendo'],
                'dolor': ['dolor', 'duele', 'molestia'],
                'v칩mitos': ['v칩mito', 'vomita', 'vomitar'],
                'diarrea': ['diarrea', 'caca', 'heces'],
                'garganta': ['garganta', 'dolor de garganta'],
                'o칤do': ['o칤do', 'oreja', 'dolor de o칤do']
            }
            
            for symptom, keywords in symptoms.items():
                if any(keyword in content for keyword in keywords):
                    context_info['has_symptom'] = True
                    context_info['symptom'] = symptom
                    break
        
        return context_info

    def _force_specific_question(self, response_text: str, phase: ConversationPhase, context_info: Dict[str, Any]) -> str:
        """Fuerza que la respuesta contenga la pregunta espec칤fica correcta"""
        
        # Obtener la pregunta espec칤fica que debe hacer
        specific_question = MedicalPrompts.get_specific_question_for_phase(phase, context_info)
        
        # Si es la fase inicial, forzar la pregunta de edad
        if phase == ConversationPhase.INITIAL:
            if "edad" not in response_text.lower() or "?" not in response_text:
                return f"Hola, soy el pediatra de DocoKids. {specific_question}"
        
        # Verificar si la respuesta ya contiene la pregunta correcta
        if specific_question.lower() in response_text.lower():
            # La pregunta est치 presente, solo validar que sea una sola
            return self._validate_single_question(response_text, phase)
        
        # Si no contiene la pregunta correcta, reemplazar o agregar
        if phase == ConversationPhase.INITIAL:
            return f"Hola, soy el pediatra de DocoKids. {specific_question}"
        else:
            # Para otras fases, intentar mantener el contexto pero agregar la pregunta correcta
            lines = response_text.split('\n')
            # Eliminar l칤neas que contengan preguntas incorrectas
            cleaned_lines = []
            for line in lines:
                if '?' not in line or specific_question.lower() in line.lower():
                    cleaned_lines.append(line)
            
            # Agregar la pregunta correcta al final
            if not any('?' in line for line in cleaned_lines):
                cleaned_lines.append(specific_question)
            
            return '\n'.join(cleaned_lines)

    def _validate_single_question(self, response_text: str, phase: ConversationPhase) -> str:
        """Valida y corrige la respuesta para asegurar que tenga solo una pregunta"""
        
        # Contar signos de interrogaci칩n
        question_marks = response_text.count('?')
        
        if question_marks == 0:
            # No hay preguntas, agregar una
            if phase == ConversationPhase.INITIAL:
                return response_text + "\n\n쮺u치l es la edad del ni침o?"
            else:
                return response_text + "\n\n쯇odr칤as contarme m치s sobre los s칤ntomas?"
        
        elif question_marks == 1:
            # Perfecto, una sola pregunta
            return response_text
        
        else:
            # M칰ltiples preguntas, simplificar
            logger.warning(f"Multiple questions detected in response: {response_text}")
            
            # Encontrar la primera pregunta y eliminar las dem치s
            lines = response_text.split('\n')
            cleaned_lines = []
            question_found = False
            
            for line in lines:
                if '?' in line and not question_found:
                    cleaned_lines.append(line)
                    question_found = True
                elif '?' not in line:
                    cleaned_lines.append(line)
            
            # Si no encontramos preguntas v치lidas, agregar una
            if not question_found:
                if phase == ConversationPhase.INITIAL:
                    cleaned_lines.append("쮺u치l es la edad del ni침o?")
                else:
                    cleaned_lines.append("쯇odr칤as contarme m치s sobre los s칤ntomas?")
            
            return '\n'.join(cleaned_lines) 